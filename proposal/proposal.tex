%\documentclass[a4paper,11pt,twoside]{article}
\documentclass[preprint,10pt,numbers]{sigplanconf}
\usepackage[utf8]{inputenc}          % UTF-8 Encoding
\usepackage{hyperref}                % Interactive PDF
\usepackage{float}                   % Float control
\usepackage{caption}                 
\usepackage{subcaption}
\usepackage{multirow}                % Span multiple rows & columns in a table
\usepackage{amsmath}                 % Mathematics library
\usepackage{amssymb}                 % Provides math fonts
\usepackage{amsthm}                  % Provides \newtheorem, \theoremstyle, etc.
\usepackage[T1]{fontenc}             % Fixes font issues
\usepackage{lmodern}
\usepackage{tikz}                    % Drawing
\usetikzlibrary{trees}
\usetikzlibrary{calc}
\usepackage{xcolor}
\usepackage{listings}

\lstset{
 backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
 basicstyle=\ttfamily\small,        % the size of the fonts that are used for the code
 commentstyle=\itshape,
 breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
 breaklines=true,                 % sets automatic line breaking
 captionpos=b,                    % sets the caption-position to bottom
 deletekeywords={...},            % if you want to delete keywords from the given language
 escapeinside={(*}{*)},          % if you want to add LaTeX within your code
 extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
 frame=none,	                   % adds a frame around the code
 keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
 numbers=none,                    % where to put the line-numbers; possible values are (none, left, right)
 rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
 showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
 showstringspaces=false,          % underline spaces within strings only
 showtabs=false,                  % show tabs within strings adding particular underscores
 tabsize=2,	                   % sets default tabsize to 2 spaces
 title=\lstname,                   % show the filename of files included with \lstinputlisting; also try caption instead of title
  belowcaptionskip=-1\baselineskip,
  xleftmargin=\parindent
}
% Links style
\lstdefinestyle{links}{
  basicstyle=\linespread{1.0}\ttfamily\footnotesize,
  language=Caml,
  frame=none,
  literate= {+}{{$+$}}1 {*}{{$*$}}1
            {<=}{{$\leq$}}1 {>=}{{$\geq$}}1 
            {=>}{{$\Rightarrow$}}1
            {->}{{$\to$}}1 {~>}{{$\rightsquigarrow$}}1
}
%\usepackage[
%backend=bibtex,
%style=numeric,
%sorting=nyt
%]{biblatex}                   % Bibliography
%\addbibresource{references.bib}


% Convenient macros
\newcommand{\defas}[0]{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}} % "defined-as-equal"

% To have line breaks in tabular cells
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

%% Meta-stuff like authors, title, etc.
%\author{Daniel Hillerström\\\small{CDT in Pervasive Parallelism}\\\small{\href{mailto:daniel.hillerstrom@ed.ac.uk}{daniel.hillerstrom@ed.ac.uk}}}
%\date{\today}
%\title{Proposal: Effective Concurrency in Links} % Just some title; change at a later point.

% The document
\makeatletter
\def\@copyrightspace{\relax}
\makeatother
\begin{document}
\title{Modular and Effective Concurrency in Functional Programming}
%\subtitle{via handlers}

\authorinfo{Daniel Hillerström}
           {CDT Pervasive Parallelism}
           {\href{mailto:daniel.hillerstrom@ed.ac.uk}{daniel.hillerstrom@ed.ac.uk}}
  \maketitle
  \begin{abstract}
Parallel and concurrent programming is challenging. However, it is important, as parallel architectures have become ubiquitous. If we are to harness the computational power of parallel architectures, then we need structured and modular programming models.

Modular and efficient task scheduling is important in order to achieve performance by picking the most suitable scheduling strategy in a given situation. However, existing programming models require the programmer to annotate blocks of code with inflexible and non-modular compiler directives. Scheduling decisions are made by a generic run-time without exploiting domain knowledge.

If scheduling strategies and tasks were expressible in the same programming language, then programmers could choose the best scheduling strategy for an application. We believe algebraic effect handlers provide a solution to this problem. Therefore, we propose to implement a compiler for Links that generates efficient run-time implementations of algebraic effect handlers. Then we will use handlers to implement modular and effective scheduling.
%The choice of scheduling strategy affects the performance of application. But often the programmer has little or no influence on the matter. There exists many tools that address this mismatch for high-performance computing. However, these tools require the programmer to describe programs in a foreign language which renders code non-modular.
%We propose a novel, efficient implementation of effect handlers in Links that uses a resource-tracking type system to enable a code generator specialise the run-time implementation of individual handlers. Furthermore, we hypothesise that we can achieve ``concurrency for free'' by encoding concurrency primitives via handlers.
  \end{abstract}
  \raggedbottom
  % Input the content
  \section{Introduction}
%Parallel and concurrent programming is about writing programs that are to be executed concurrently.
During the past decade parallel architectures have become pervasive, especially due to the recent emergence of multicore smartphones. It is difficult to utilise multiple homogeneous processing cores effectively, and the problem is no easier when we consider heterogeneous processing cores. 
Scheduling is at the heart of parallel and concurrent programming as it is concerned with when computations are executed or suspended. 
Run-time scheduling is an important problem as the performance goal of a scheduler can be paramount to the overall performance of a program. For example, system schedulers seek to optimise the job throughput. Resource schedulers attempt to ensure fairness by coordinating accesses to shared resources. Task schedulers seek to reduce execution time by considering factors such as dependencies among tasks. In addition, task schedulers may also seek to exploit special-purpose accelerators in the environment in order to speed up task execution.

Clearly, the performance goals of different schedulers may conflict with each other. Furthermore, a scheduler may employ different \emph{scheduling strategies} to achieve its performance goal. The choice of scheduling strategy depends on the problem domain.
For instance, stencil computations may benefit from neighbouring points being scheduled together.
However, in most programming models the programmer has little or no say regarding scheduling. The programmer's involvement is often limited to annotating blocks of code with compiler directives. But this approach is not modular, because computations and scheduling strategies are hard-wired together. Consequently, it is nontrivial to change or reuse a particular scheduling strategy. In addition, the compiler is free to ignore the programmer's annotation.
% Many different domains, we want modularity

%Consequently, schedulers employ different metrics to measure performance. For example, \emph{high-throughput} schedulers seek to optimise the throughput of jobs \cite{Berman2003}, hence performance might be measured by the number of jobs processed by the system. Criteria such as fairness or utilisation might be used to measure the performance of \emph{resource} schedulers as they seek to coordinate accesses to shared resources \cite{Berman2003}. Furthermore, \emph{high-performance} schedulers seek to minimise execution time for a single program. In this case performance is measured by the raw execution speed.

%For example, the application programmer's knowledge of the problem domain may accelerate program execution grid-based computations may benefit from neighbouring points being scheduled together. Yet the programmer has little or no say about the matter as schedulers typically are baked into the run-time system \cite{Dolan2015}. 

%We advocate a modular approach which enables the programmer propose to rectify this mismatch by transferring the responsibility for scheduling to the application programmer. 
We advocate an approach that decouples the implementation of tasks from scheduling strategies.
Concretely, we propose to abstract over the choice of scheduling strategy by adapting the approach taken by Multicore OCaml \cite{Dolan2015} to use Plotkin and Pretnar's \emph{handlers for algebraic effects} \cite{Plotkin2013} to encode scheduling strategies. Specifically, we plan implement a backend for the functional programming language Links \cite{Cooper2006}, and take advantage of its existing implementation of algebraic effect handlers \cite{Hillerstrom2015} to encode Links' message-passing concurrency model.

  % Plotkin and Power's algebraic effects \cite{Plotkin2001} combined with Plotkin and Pretnar's handlers \cite{Plotkin2013} yield a programming model for controlling computational effects. An algebraic effect is a collection of abstract operations without predefined semantics. Handlers interpret algebraic effects by assigning semantics to abstract operations. Thus, the control of computational effects is lifted from the run-time system into the hands of the programmer. Clearly, it shifts additional responsibility onto the programmer, however, in addition it opens up a design space that was previously secluded from the programmer. Now, the programmer may extend the capabilities of the run-time system beyond what the language implementor envisaged.

  % For example, it is well-known that concurrency primitives can be encoded through algebraic effects \cite{Bauer2015,Dolan2015} as spawning a new thread is an effect. Furthermore, suspending a thread is an effect. Handlers of these effects are schedulers. Hence, the programmer is free to implement a particular scheduling policy tailored for the application. The choice of scheduler can have significant impact on performance as a scheduler's performance goal can be paramount to the overall performance of an application \cite{Berman2003}.

  % However\dots

  \section{Problem definition}\label{sec:problemdefinition}
%  Although, handlers for algebraic effects have many practical applications \cite{Kammar2013,Bauer2015,Hillerstrom2015,Dolan2015}, there does not yet exist an efficient implementation of handlers. Multicore OCaml implements linear handlers which only allow the continuation invoked once. This restriction is enforced during run-time. Furthermore, because OCaml lacks an effect system\dots
%Run-time scheduling is recognised as an important problem for performance \cite{Augonnet2011,Augonnet2012,Agullo2015,Openmp2013}. 
There exists many concurrent and parallel programming models that attempt to involve programmer participation in scheduling, e.g. CellSs \cite{Bellens2009}, StarSs \cite{Planas2009}, StarPU \cite{Augonnet2011}, OpenMP \cite{Openmp2013} Chapel \cite{Chapel2012} and X10 \cite{X102015} to mention a few established ones.\footnote{These programming models are further discussed in Section \ref{sec:relatedwork}.}
These programming models operate on task graph based descriptions of programs. They map individual tasks onto computational devices automatically.

However, the disadvantage is, that they provide weak abstractions making scheduling non-modular. The programmer has to resort to compile-time meta programming in a foreign language such as \texttt{\#pragmas} to influence scheduling. As a consequence the implementation of scheduling strategies and tasks become tightly coupled which makes it nontrivial to swap scheduling strategies. Moreover, if one combines these programming models; what are the semantics of the resulting programming model then?
% Moreover, the programmer still has a limited say.
% End up with a monolithic tools

If we were able to express scheduling strategies and tasks independently of each other, but in the same programming language, then we would be able to give precise semantics. In particular, we would achieve modularity naturally. Therefore, we ask the following question:
\begin{center}
  \emph{How may we reify scheduling strategies as an integrated construct in the host language?}
\end{center}
In Section \ref{sec:proposedsolution} we propose an answer to the question.

\section{Background}\label{sec:background}
In Section \ref{sec:effects-and-handlers} we introduce algebraic effects and handlers, while in Section \ref{sec:effect-links} we introduce an implementation of them in the functional language Links.

\subsection{Algebraic effects and their handlers}\label{sec:effects-and-handlers}
Plotkin and Power introduced algebraic effects \cite{Plotkin2001} for modelling the semantics of effectful computations \cite{Lindley2014}. An algebraic effect is a collection of abstract operations. For example, we might define an algebraic effect for state: $State(s) \defas \{Get:s,Put:s \to ()\}$. State is an effect with two operations: Get and Put which retrieve and modify some state $s$, respectively. The State effect and its operations do not have predefined semantics.

% \begin{figure*}[t!]
% \begin{subfigure}[b]{0.5\textwidth}
% \centering
% \begin{lstlisting}[caption={},style=links]
% sig withdraw : (*$(\texttt{Int}) \xrightarrow{\texttt{\{Get:Int},\texttt{Put:(Int)} \to ()|\varepsilon\}} \texttt{Int}$*)
% fun withdraw(amount) {
%   var balance = get();
%   if (balance - amount > 0) {
%     put(balance - amount); amount
%   } else {
%     0
%   }
% }
% \end{lstlisting}
% \caption{Computation tree for \dots}\label{fig:effecttree}
% \end{subfigure}
% ~
% \begin{subfigure}[b]{0.5\textwidth}
% \centering
% \begin{tikzpicture}[level distance=1.5cm,
% level 1/.style={sibling distance=3.5cm},
% level 2/.style={sibling distance=2cm}]
% %\tikzstyle{every node}=[circle,draw]

% \node (Root) [blue,rectangle] {Get}
%     child { node[blue] (q0) {Put} 
%       child { node[draw=none] (q00) {\texttt{amount}}
%         edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {()}
%       }      
%       edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {\texttt{balance}}
%     }
%     child { node [draw=none] (q1) {0}
%       edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {\texttt{balance}}
%     };
% \end{tikzpicture}
% \caption{Computation tree for \dots}\label{fig:effecttree}
% \end{subfigure}
% \caption{Computation and its computation tree.}
% \end{figure*}

Handlers assign semantics to effects. Essentially, handlers interpret invocations of abstract operations in computations. Handlers may be either closed or open. A closed handler handles a fixed set of effects, whilst an open handler handles a subset of effects. Open handlers can be composed together to handle a larger set of effects. In addition, handlers comes in two different flavours: \emph{deep} or \emph{shallow}. Deep handlers interpret operations uniformly, e.g. every occurrence of Get is interpreted by the same handler. Conversely, shallow handlers interpret operations non-uniformly as operations are not necessarily interpreted by the same handler every time. Both types of handlers have practical applications \cite{Kammar2013}.

% Intuitively handlers fold computation trees

%\subsection{Continuations}\label{sec:continuations}

  \subsection{Links with effect handlers}\label{sec:effect-links}
Links is functional programming language \cite{Cooper2006} with a strong type and effect system. Notably, Links implements both deep and shallow effect handlers as first-class citizens \cite{Hillerstrom2015}. Intuitively, handlers are interpreters that pattern matches on abstract operations occurring in some handled computation. This is directly reflected in the syntax for handlers. As an example consider the following handler which interprets the State effect introduced in the previous section:
\begin{lstlisting}[style=links,caption={}]
sig state : (*$\left(() \xrightarrow{\{Get:s,Put:s\to()\}} a\right) \to (s) \to a$*)
handler state(m)(s) {
  case Get(k)    -> k(s)(s)
  case Put(p,k)  -> k(())(p)
  case Return(x) -> x
}
\end{lstlisting}
The signature for \texttt{state} conveys that it handles some computation \texttt{m} whose effect signature contains (only) \texttt{Get} and \texttt{Put}, the computation returns a value of type \texttt{a}. The second parameter \texttt{s} is the program state which the computation \texttt{m} may modify.
The case-statements pattern matches on the operation names in effect signature of \texttt{m}.
The cases \texttt{Get} and \texttt{Put} matches on user-defined operations, while the \texttt{Return} operation is a special, built-in operation that is invoked implicitly, when the computation \texttt{m} returns.

When an operation is invoked in \texttt{m} the run-time generates a continuation from that point in the program. Then the run-time transfers control to the handler which exposes this continuation is to the programmer via the parameter \texttt{k} in the case-statements. For example, when \texttt{Get} is invoked this particular handler invokes the continuation with the current state \texttt{s}. This effectively resumes the computation \texttt{m} with the state \texttt{s}. Moreover, the same state \texttt{s} is forwarded to the next invocation of the handler. In the case of \texttt{Put}, the handler invokes the continuation with unit, and forwards the new state \texttt{p} to subsequent invocations of the handler.

At the time of writing effect handlers are only supported by the Links interpreter. Thus the performance of handlers is low.

  \section{Proposed solution}\label{sec:proposedsolution}
%The main observation is, that, tools often happen to offer poor abstractions which requires the programmer to annotate or describe code in \emph{a foreign language}. As a consequence code becomes non-modular, and thus, it difficult to combine different pieces of code.
We advocate an approach along the lines of Multicore OCaml to use algebraic effect handlers to encode concurrency directly in the host language. 
%Algebraic effects combined with handlers yield a programming model which provide a clear separation of computational effects and their interpretations.

The key observation is that concurrent and parallel concepts such as task forking, kernel launch and data-sharing can be thought of as effectful computations. Concurrency is encodable through algebraic effects \cite{Bauer2015,Dolan2015}. Handlers will be used to implement scheduling strategies. In Sections \ref{sec:eff} and \ref{sec:sched} we give a concrete example of a possible encoding of asynchronous tasks, and two possible task schedulers.

\subsection{Encoding cooperative multitasking}\label{sec:eff}
We may encode \emph{cooperative multitasking} using the following two operations:
\begin{itemize}
  \item $\text{fork} : (() \to a) \to F a$
  \item $\text{yield} : ()$
\end{itemize}
The first operation \emph{fork} takes a task as input, and returns a future which eventually will contain the result of the said task. The second operation \emph{yield} suspends the task in which it was invoked. Using these operations we can easily define an asynchronous computation that computes the $n$th Fibonacci number, e.g. 
\begin{lstlisting}[style={links},caption={}]
fun fib(n) {
  if (n <= 1) {n}
  else {
    var f1 = fork(fun() { fib(n-1) });
    var f2 = fork(fun() { fib(n-2) });
    getf(f1) + getf(f2)
  }
}
\end{lstlisting}
where \texttt{getf} attempts to retrieve the value inside a future. Its implementation is omitted here, but it is simple to implement in terms of yield.\footnote{The full source code is available at \url{https://raw.githubusercontent.com/dhil/mscr-dissertation/proposal/proposal/coroutines.links}} 

\subsection{Scheduling tasks}\label{sec:sched}
Next, we are going to implement two schedulers, for the Fibonacci computation, as handlers.
First, we implement a scheduler that explores the computation tree in a breath-first manner:
\begin{lstlisting}[style={links},caption={}]
open handler sched(m)(f) {
  case Fork(t,k) -> {
   var new_f = new_future();
   enqueue(fun(_){sched(t)(Just(new_f))()});
   k(new_f)(f)
  }
  case Yield(k)  -> { 
   enqueue(fun(_) { k(())(f) }); 
   var t = dequeue(); t(()) 
  }
  case Return(x) -> {
     putf(f,x);
     if (is_empty()) { x }
     else { var t = dequeue(); t(()) }
   } 
}
\end{lstlisting}
The handler \texttt{sched} implements a scheduler with a particular scheduling strategy by pattern matching on occurrences of operations \texttt{Fork} and \texttt{Yield} in some computation \texttt{m}. The handler is parameterised by a future \texttt{f}. For instance, when \texttt{fork} occurs in \texttt{fib} the scheduler first allocates a new future \texttt{new\_f}. Then it recursively schedules the forked task \texttt{t} to run later. Finally, it resumes the task in which \texttt{t} was forked by invoking the continuation \texttt{k} with the new future \texttt{new\_f}, the previous future \texttt{f} is saved for the next invocation of the scheduler. Observe, that on a single-core platform this scheduling strategy effectively defers execution of forked tasks.

Upon an occurrence of \texttt{yield} in \texttt{m} the handler suspends the task and schedules it to run later. Thereafter it dequeues and resumes another task \texttt{t}.

Finally, when a task finishes the handler puts the return value inside the future \texttt{f}. Furthermore, if the task queue is nonempty it dequeues and resumes another task, otherwise it the result of latest task is returned.
\begin{figure*}[t!]
\begin{subfigure}[t]{0.5\textwidth}
\centering
\begin{tikzpicture}[level distance=1.5cm,
level 1/.style={sibling distance=3.5cm},
level 2/.style={sibling distance=2cm}]
%\tikzstyle{every node}=[circle,draw]

\node (Root) [blue,rectangle] {fib(3)}
    child { node[blue] (q0) {fib(2)} 
      child { node[blue] (q00) {fib(1)}
        child { node[draw=none] {1} }
        edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {$f_3$}
      }
      child { node[blue] (q01) {fib(0)} 
        child { node[draw=none] {0}         
        }
        edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {$f_4$}
      }
      edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {$f_1$}
    }
    child { node [blue] (q1) {fib(1)}
      child { node[draw=none] (q10) {1}
      }
      edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {$f_2$}
    };
\end{tikzpicture}\caption{Breadth-first scheduling.}\label{fig:bfs}
\end{subfigure}
~
\begin{subfigure}[t]{0.5\textwidth}
\centering
\begin{tikzpicture}[level distance=1.5cm,
level 1/.style={sibling distance=3.5cm},
level 2/.style={sibling distance=2cm}]
%\tikzstyle{every node}=[circle,draw]

\node (Root) [blue,rectangle] {fib(3)}
    child { node[blue] (q0) {fib(2)} 
      child { node[blue] (q00) {fib(1)}
        child { node[draw=none] {1} }
        edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {$f_2$}
      }
      child { node[blue] (q01) {fib(0)} 
        child { node[draw=none] {0}         
        }
        edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {$f_3$}
      }
      edge from parent node [draw=none,left,xshift=-2.0,yshift=2.0] {$f_1$}
    }
    child[dashed] { node [blue] (q1) {fib(1)}
      child[solid] { node[draw=none] (q10) {1}
      }
      edge from parent node [draw=none,right,xshift=2.0,yshift=2.0] {$f_2'$}
    };
\end{tikzpicture}\caption{Depth-first scheduling. Note $f_2$ and $f_2'$ are disjoint tasks.}\label{fig:dfs}
\end{subfigure}\caption{Task labelled computation trees for \texttt{fib($3$)}.}
\end{figure*}

This scheduling strategy is suboptimal for the Fibonacci computation on single-core platform, because it unnecessarily materialises the entire computation tree of \texttt{fib($n$)}. Figure \ref{fig:bfs} depicts the computation tree for \texttt{fib($3$)}. The labels $f_i$ indicate tasks, and the subscripts $i$ their respective global id.

The scheduler fails to exploit the fact that a parent task depends on its two children tasks. We can remedy this issue by eagerly execute forked tasks. Visually, this policy to correspond to visiting the computation tree in a depth-first manner. Such a scheduler is similar to the \texttt{sched}, we only need to change queuing policy in the \texttt{Fork}-case, e.g.
\begin{lstlisting}[style={links},caption={}]
case Fork(t,k) -> {
 var new_f = new_future();
 enqueue(fun(_) { k(new_f)(f) });
 sched(t)(Just(new_f))()
}
\end{lstlisting}
Instead of enqueuing the forked task, we enqueue the continuation to run later. Moreover, we eagerly execute the forked task \texttt{t}.
Figure \ref{fig:dfs} depicts the labelled computation tree for \texttt{fib($3$)} when using this scheduler. Now, the entire computation tree no longer needs to materialised. The space used for tasks in the left subtree can be reused for subsequent tasks in the right subtree. Obviously, we save space, but it has a further subtle impact: The tasks yield fewer times which implies the scheduler is invoked fewer times. Thus, we reduced the overhead incurred by the scheduler. In the case of \texttt{fib($n$)} it means we, presumably, achieve a small improvement in performance.

Admittedly, the Fibonacci computation is trivial, and we are unlikely to encounter such a trivial computation in any practical application. However, the take away point from this example is, that, we were able change schedulers independently of the computation. Furthermore, we envision that it might be possible to implement scheduler that employ memorisation to optimise computations with repetitive tasks such as the naïve Fibonacci.

Essentially, we derived the sequential schedule for the naïve Fibonacci implementation. If we were to execute the computation on multicore platform, then the breadth-first scheduler would be a better choice. Fortunately, with this programming abstraction it is easy to change schedulers as computations and schedulers are expressed in the same language. In other words: We gain modularity. But this simple exercise is nontrivial in established programming models.

\subsection{Proposal}
We propose to give implement a compiler for the Links programming language that produces efficient run-time implementations of effect handlers. In addition, we hypothesise that the handler abstraction is strong enough for us to achieve modular concurrency. By modular concurrency, we mean that we can change the actual scheduling strategy for processes or threads. Furthermore, we believe that we can encode Links' message-passing concurrency model using handlers. 
%Provided that the implementation of handlers is efficient, then this should give us ``concurrency for free''.

\subsection{Project outcomes}
There will be at least two outcomes from this project:
\begin{itemize}
  \item An efficient implementation of effect handlers.
  \item An account of concurrent programming with effect encoded concurrency.  
\end{itemize}

\section{Methodology}
The power of handlers comes from the continuation. At the same time, it is the greatest performance killer, since a continuation is a copy of current stack state.
%A continuation captures the remainder of a computation. On run-time this means a continuation is a copy of the current stack state, and to invoke a continuation is to return a copy of the stack. In general, handlers allow continuations to be invoked multiple times, thus the run-time has to maintain multiple copies of different stack states. This is expensive.
However, one can observe that in many cases continuations are only invoked once, these are called single-shot continuations. A single-shot continuation can be implemented efficiently \cite{Bruggeman1996}. But if we restrict all continuations to be single-shot, then the programming model loses a lot of power. Instead we can classify handlers according to how many times they invoke continuations: 
\begin{description}
  \item[0 times] \emph{Exception handlers}; no need for continuations.
  \item[1 time] \emph{Linear handlers}; can be implemented efficiently.
  \item[More than 1 time] \emph{Multi-handlers}; no known general efficient implementation.
\end{description}
We can take advantage of Links' type system to track this information, then in the code generation phase we may use this information to specialise implementations of particular handlers\footnote{This idea originated in a discussion with Sam Lindley.}.

  \section{Related work}\label{sec:relatedwork}
In section we briefly summarise related work.

  \subsection{Concurrent and parallel programming models}
\begin{table*}
\centering
\begin{tabular}{| l | l | l |}
\hline
 \textbf{Language}             & \textbf{Programming model} & \textbf{Memory model}\\
\hline
MPI \cite{Mpi2012} & Message-passing          & Distributed memory  \\
\hline
PaRSEC \cite{Bosilca2013}      & Dataflow programming & Shared memory \& distributed memory  \\
\hline
OpenACC \cite{Openacc2013}     & Annotations via pragmas; Data parallel & Shared memory \\
\hline
\specialcell[c]{\shortstack[l]{CellSs \cite{Bellens2009}, StarSs \cite{Planas2009},\\ StarPU \cite{Augonnet2011}, OpenMP \cite{Openmp2013}}} & Annotations via pragmas; API & Shared memory \\
\hline
\specialcell[c]{\shortstack[l]{Chapel \cite{Chapel2012}, X10 \cite{X102015},\\ Unified Parallel C \cite{Upc2013},\\ Coarray Fortran \cite{Reid2005}}} & Shared variable programming & Partitioned Global Address Space \\
\hline
\end{tabular}
\caption{Classification of a selection of concurrent and parallel programming models.}\label{tbl:models}
\end{table*}
Several programming languages attempt to address the problem of scheduling in high-performance computing. A selection of these programming models is listed in Table \ref{tbl:models}.

CellSs \cite{Bellens2009} provide a source-to-source compiler that translates annotated C or Fortran code. It attempts to automatically derive opportunities for task-based concurrency. StarSs \cite{Planas2009} and StarPU \cite{Augonnet2011} are influenced by CellSs. The former extends CellSs with hierarchical task scheduling. StarPU provides a unified platform for dynamic scheduling on heterogeneous multicore architectures. All three has influenced the open industry standard OpenMP \cite{Openmp2013}. 

PARSeC \cite{Bosilca2013} is a generic architecture-aware framework for task scheduling in heterogeneous environments. The run-time operate on task dependency graphs, thus the run-time engine is aware of both the tasks to be executed and the dataflow which connects them. The dataflow representation enables the run-time to handle communication between processes automatically. The run-time inserts synchronisation points whenever necessary.

OpenACC \cite{Openacc2013} is an open standard for accelerator programming. It uses a combination of programmer annotations via \texttt{\#pragmas} and APIs in much the same fashion as OpenMP. However, OpenACC focuses exclusively on data parallelism, whereas OpenMP is much broader in its focus.

MPI is a message-passing model for distributed programming \cite{Mpi2012}. Programs in MPI are written in Single Program, Multiple Data (SPMD) style. That means all processes execute the same program, but each process may follow designated parts of the program. Data sharing among processes happens via message passing. Communication is two-sided as processes must actively participate in the data-sharing either by sending or receiving.

Chapel \cite{Chapel2012}, Coarray Fortran \cite{Reid2005}, X10 \cite{X102015} and Unified Parallel C \cite{Upc2013} are so-called Partitioned Global Address Space (PGAS) languages. This programming model provide a shared memory programming interface to distributed programming. All communication between processes are single-sided, i.e. a process can directly manipulate the memory of some remote process.

\subsection{Multicore OCaml}
OCaml is a functional language with an industrial strength compiler. The Multicore OCaml project \cite{Dolan2015} attempts to bring multi-core capabilities to the OCaml language by using deep handlers to encode concurrency. The implementation of handlers is restricted to so-called \emph{linear handlers}, i.e. handlers which only invokes the continuation parameter once. However, this restriction is not enforced statically, therefore multiple invocations of a continuation result in a run-time error. Moreover, OCaml does not have an effect system.

%\subsection{The Links intermediate representation}
%The Links compiler uses A-normal form (ANF) as its intermediate representation for programs. ANF is the functional equivalent to the imperative Static Single Assignment form. All arguments to a function must be let-bound \cite{Flanagan1993}. This restriction makes it easy to build continuations.

%  \subsection{Optimisation of single-shot continuations}

%   \subsection{Handlers implementations}
%   This section briefly surveys existing implementations of effect handlers. Section \ref{sec:first-class} considers languages with first-class handlers, whilst Section \ref{sec:library} discusses embeddings of handlers in the pure functional programming language Haskell.
%   \subsubsection{First-class implementations}\label{sec:first-class}
%   \begin{table}[H]
%     \centering 
%     \begin{tabular}{| l | l | l |}
%       \hline
%       \multicolumn{1}{|c|}{Language} & \multicolumn{1}{c|}{Handlers} & \multicolumn{1}{c|}{Developed by} \\
%       \hline
%       Eff & Deep handlers & Bauer and Pretnar \\ 
%       \hline
%       Frank & Shallow handlers & McLaughlin, Lindley and McBride \\    
%       \hline
%       Links & Shallow and deep handlers & Hillerström and Lindley\\
%       \hline
%       Multicore OCaml & Deep handlers & OCamlLabs \\
%       \hline    
%     \end{tabular}\caption{Languages with first-class effect handlers.}\label{tbl:impls}
%   \end{table}
%   Table \ref{tbl:impls} provide an overview of languages where effect handlers are first-class citizens. 

% The Eff language is a OCaml-style language with deep handlers. It support for effect polymorphism through subtyping \cite{Bauer2015}. 
% The functional programming Links implements both deep and shallow handlers \cite{Hillerstrom2015}. Moreover, the implementation supports effect polymorphism through Links' existing row polymorphic effect system.
    
%   \subsubsection{Library implementations}\label{sec:library}

  \section{Evaluation}
  The primary metric for evaluation of the compiler will be performance of programs produced by it. We intend to mainly measure performance by raw execution speed. Furthermore, we intend to compare our performance results against results for similar programs written in C since it is considered a ``performant'' language. We will measure the performance on standard multicore desktop machine (Intel i5 CPU).

Additionally, we will consider the safety of our solution, i.e. which static guarantees, if any, can we exhibit. In order to evaluate safety we intend to give a formal proof of the said properties.

Furthermore, we would like to qualitatively assess the ease of use, that is, whether the handler abstraction makes concurrent programming easier.

  \section{Project plan}
  \begin{table}[H]
    \centering
    \begin{tabular}{ | l | c | c | c | c | c | }
      \hline
      \multicolumn{1}{|c|}{Activity / Weeks} & 2-4 & 5-9 & 10-18 & 19-21 & 22-33 \\
      \hline
      Finding examples & X & X & & & \\
      \hline      
      Related work   & X  & X &  &   & X \\
      \hline
      Benchmarks     & X & X & X & & \\
      \hline
      Prototyping    & X & X & & & \\
      \hline
      Implementation &  & X & X & X  & X \\
      \hline
      Testing        &  & X & X &  & X \\
      \hline
    Single-core eval. &   &  & X &  &  \\
      \hline
    Multi-core eval. &   &  &    & X  & X \\
      \hline
      Safety eval. &   &   &  &  & X \\
      \hline
      Write up       & X & X & X & X  & X  \\
      \hline
    \end{tabular}\caption{Coarse-grained activity overview.}\label{tbl:activities}
  \end{table}
Table \ref{tbl:activities} provide a high-level overview for the activities during this project. The first three activities are connected. The idea is to survey related and background material to find examples and applications that we can use to build a benchmark suite. Furthermore, we intend to revisit the related work activity during later phases of the project in order to potentially include and discuss the latest work in the dissertation.

The prototyping and implementation activities are connected aswell. We are going to create some prototype implementations based on the examples and applications that we found. These prototypes will possibly be use-case specific, however, the idea is to use them as a starting point for the implementation of the general solution.
The implementation activity is going to be the main activity which is reflected in the table. The activities implementation and testing could arguably have been combined into one activity, however, here we have separated them to emphasise the importance of both activities. The idea is to adopt an agile development approach by decomposing the implementation activity into many small tasks. The duration of a single task should be at most one week. Furthermore, we will have automated regression testing that tests the correctness of the implementation. This ought to ensure that sensible progress is made (at least up to the test coverage).

Evaluation will become a natural extension of the testing activity. We split evaluation into three activities: Single-core, multi-core and safety. First we will evaluate the performance of programs that use a single core. Test programs will include both concurrent and sequential programs. Later, this activity will be subsumed by the multi-core activity in which we will consider parallel execution of programs.
During the evaluation activities we shift the focus from correctness to fulfilment of our goals. The implementation will be evaluated weekly with regard to the performance goals. Possibly, this will be automated to a certain extent. Evaluation of safety and ease of use will be done manually. The former is a pencil and paper exercise, while the latter requires a subjective comparison of code examples.

The dissertation write up is supposed to be a continuous activity. The aim is to produce a work sheet per week that reflects the work done in the other activities. They will act as a sort of worklog. Moreover, the worksheets are not necessarily meant to become part of the dissertation. But as we approach the hand-in deadline, we will shift more focus onto writing up the actual dissertation. Hopefully, the worksheets can provide the foundation for the dissertation.

  % Bibliography
\bibliographystyle{abbrv}
\softraggedright
%\nocite{*}
\bibliography{references}
%  \printbibliography[heading=bibintoc]
\end{document}